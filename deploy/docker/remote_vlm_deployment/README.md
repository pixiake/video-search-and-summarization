# VSS å¿«é€Ÿéƒ¨ç½² - ä½¿ç”¨è‡ªå·±çš„ LLM + é˜¿é‡Œäº‘ Qwen3-VL

## ç¬¬ 1 æ­¥ï¼šä¿®æ”¹ .env æ–‡ä»¶

```bash
nano .env
```

å¡«å†™ä»¥ä¸‹å†…å®¹ï¼ˆ**åªéœ€ä¿®æ”¹è¿™5è¡Œ**ï¼‰ï¼š

```bash
# ç¬¬ 3 è¡Œ - ä½ çš„é˜¿é‡Œäº‘ API Key
VIA_VLM_API_KEY=sk-xxxxx

# ç¬¬ 8 è¡Œ - ä½ çš„ LLM æ¨¡å‹åç§°ï¼ˆOpenAI æ ¼å¼ï¼‰
LLM_MODEL_NAME=qwen2.5-72b-instruct

# ç¬¬ 9 è¡Œ - ä½ çš„ LLM æœåŠ¡åœ°å€
LLM_BASE_URL=http://192.168.1.100:8000/v1

# ç¬¬ 14 è¡Œ - ä½ çš„ Embedding æ¨¡å‹åç§°
EMBEDDING_MODEL_NAME=bge-m3

# ç¬¬ 15 è¡Œ - ä½ çš„ Embedding æœåŠ¡åœ°å€
EMBEDDING_BASE_URL=http://192.168.1.100:8001/v1
```

ğŸ’¡ **æ³¨æ„**: 
- å¦‚æœ LLM/Embedding ä¸éœ€è¦ API Keyï¼Œä¿æŒ `LLM_API_KEY` ä¸ºç©ºå³å¯
- å¦‚æœæ²¡æœ‰ Rerankerï¼Œå¯ä»¥ä¸å¡«æˆ–ä½¿ç”¨ç›¸åŒçš„ Embedding æœåŠ¡

---

## ç¬¬ 2 æ­¥ï¼šå¯åŠ¨æœåŠ¡

```bash
# ç¡®ä¿ Docker æ­£åœ¨è¿è¡Œ
docker compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f via-server
```

---

## ç¬¬ 3 æ­¥ï¼šè®¿é—® UI

æµè§ˆå™¨æ‰“å¼€ï¼š**http://localhost:9100**

---

## åœæ­¢æœåŠ¡

```bash
docker compose down
```

---

## æ•…éšœæ’æŸ¥

### æŸ¥çœ‹æ—¥å¿—
```bash
docker compose logs -f via-server
```

### æµ‹è¯• API
```bash
# æµ‹è¯•å¥åº·çŠ¶æ€
curl http://localhost:8080/health

# æµ‹è¯• LLM è¿æ¥
curl http://ä½ çš„LLMæœåŠ¡åœ°å€/v1/models
```

### é‡å¯æœåŠ¡
```bash
docker compose restart via-server
```

---

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰

